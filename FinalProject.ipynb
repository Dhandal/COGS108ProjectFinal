{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project\n",
    "\n",
    "### Overview\n",
    "\n",
    "Some of our group members have an interest in Japanese anime and manga. Sometimes, we wanted to find a new anime or manga to binge but sadly it’s hard to find good ones that are suited to our taste. So thus, we have the follow question we would like to answer.\n",
    "\n",
    "### Names\n",
    "\n",
    "- Aaron Lee\n",
    "- Cassie Zhu\n",
    "- Tina Chen\n",
    "- Dillon Handal\n",
    "- Emery Lin\n",
    "\n",
    "### Research Question\n",
    "\n",
    "Can we predict whether or not a user will like a certain anime or manga based on previous ratings?\n",
    "\n",
    "### Background & Prior Work\n",
    "\n",
    "This project is quite similar to movie recommendations except that we are examining a different type of dataset and medium. Thus, we can apply similar concepts that are quite useful. For example in this whitepaper, https://beta.vu.nl/nl/Images/werkstuk-fernandez_tcm235-874624.pdf, there are discussions of several approaches to Netflix movie recommender system. You can have a basic model that just recommends the popular titles; however, this approach may not be the most accurate given that users may not like the popular titles. For a more precise prediction, you can examine how close users could be or in fact, examine the similarity between the titles in terms of synopsis or content. \n",
    "\n",
    "In the pursuit to find a strong and accurate predictor, the whitepaper reveals comparisons of different models. Given the results of the comparison, they provide somewhat of a roadmap for routes or ideas we can possibly explore. We can try different types of models using all the available data in our dataset. This way we can plot and analyze the data to get meaningful conclusions about our question.\n",
    "\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "Our hypothesis is that given a user’s ratings list, we will be able to predict that a user would like a new anime or manga based on the various factors and attributes in the anime or manga from their current ratings list. We expect to see a strong correlation in some areas such as genre, popularity, and content.\n",
    "\n",
    "We believe in this hypothesis because the features given are strongly correlated with each other and are relevant features in getting predictions and understanding how they relate to each other to predict high ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Our datasets will consist of public data only. We chose to use public data because it is what’s mostly readily available and easily searched for. Our main source of data will be from the MyAnimeList website because it has the largest consolidation of the anime and manga titles as well as user rating lists. \n",
    "\n",
    "https://myanimelist.net/ - According to the MyAnimeList website forum, the statistics list over 6.5 million users. While a small fraction of users may be just dummy or throwaway accounts, the majority of users have actual ratings lists that we can use in our analysis. If we need to scrape this, we can use an API but we will also need to clean up the dataset so it is usable and there are no odd inputs.\n",
    "\t\n",
    "https://www.kaggle.com/CooperUnion/anime-recommendations-database - This dataset from Kaggle has already parsed and filtered out sensitive information. It has some useful information that we can examine. We also do not have to clean up the data for use.\n",
    "\n",
    "https://jikan.moe/ - This API can be used to interface with MAL’s website to get useful information without having to scrape and parse the website manually. It will be important in being able to get more features to examine in solving our question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure libraries\n",
    "# The seaborn library makes plots look nicer\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "# Don't display too many rows/cols of DataFrames\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 10\n",
    "\n",
    "# Round decimals when displaying DataFrames\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will scrape MAL for its recent users and get information about what they decide to publicly list on their profile and ratings lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions for getting user data\n",
    "\n",
    "def get_recent_users():\n",
    "    \"\"\" Returns recent users \"\"\"\n",
    "    r = requests.get('https://myanimelist.net/users.php', timeout=10)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "        # Finds recent users td\n",
    "        td = soup.find_all('td', attrs={'align':'center', 'class':'borderClass'})\n",
    "        users = []\n",
    "\n",
    "        # Appends users to a list\n",
    "        for e in td:\n",
    "            users.append(e.find('div').text)\n",
    "        return users\n",
    "    \n",
    "def getUserInformation(user):\n",
    "    if user is not \"\":\n",
    "        return requests.get('https://api.jikan.moe/v3/user/{}/profile'.format(user)).text\n",
    "    return None\n",
    "\n",
    "def insertInfoIntoDataFrame(df, info):\n",
    "    info = json.loads(info)\n",
    "    local = pd.DataFrame({'username': [info['username']],\n",
    "                          'location': [info['location']],\n",
    "                          'Anime-Watching': [info['anime_stats']['watching']],\n",
    "                          'Anime-Completed': [info['anime_stats']['completed']],\n",
    "                          'Anime-Total': [info['anime_stats']['total_entries']],\n",
    "                          'Anime-Mean-Score': [info['anime_stats']['mean_score']],\n",
    "                          'Manga-Reading': [info['manga_stats']['reading']],\n",
    "                          'Manga-Completed': [info['manga_stats']['completed']],\n",
    "                          'Manga-Total': [info['manga_stats']['total_entries']],\n",
    "                          'Manga-Mean-Score': [info['manga_stats']['mean_score']]})\n",
    "    local = local.set_index('username')\n",
    "    df = df.append(local)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInfo = pd.DataFrame()\n",
    "\n",
    "# Insert column headers to userInfo DataFrame\n",
    "userInfo['username'] = \"\"\n",
    "userInfo['location'] = None\n",
    "userInfo['Anime-Watching'] = 0\n",
    "userInfo['Anime-Completed'] = 0\n",
    "userInfo['Anime-Total'] = 0\n",
    "userInfo['Anime-Mean-Score'] = 0\n",
    "userInfo['Manga-Reading'] = 0\n",
    "userInfo['Manga-Completed'] = 0\n",
    "userInfo['Manga-Total'] = 0\n",
    "userInfo['Manga-Mean-Score'] = 0\n",
    "userInfo = userInfo.set_index('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = True\n",
    "\n",
    "# Grabs a bunch of recent users and inserts them into the userInfo DataFrame\n",
    "for i in range(20):\n",
    "    \n",
    "    # variable to skip downloading as this takes a long time\n",
    "    if skip:\n",
    "        continue\n",
    "    \n",
    "    # iterates 10 times and waits 5 seconds in between fetching new users\n",
    "    for user in get_recent_users():\n",
    "        userInfo = insertInfoIntoDataFrame(userInfo, getUserInformation(user))\n",
    "        sleep(2)\n",
    "    sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    userInfo.to_csv('userInfo.csv')\n",
    "else:\n",
    "    userInfo = pd.read_csv('userInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for parsing anime list\n",
    "def getAnimeList(user):\n",
    "    if user is not \"\":\n",
    "        r = requests.get('https://api.jikan.moe/v3/user/{}/animelist'.format(user))\n",
    "        if r.status_code == 200:\n",
    "            return r.text\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def insertAnimeUser(df, info, name):\n",
    "    if info is None:\n",
    "        return df\n",
    "    \n",
    "    info = json.loads(info)\n",
    "    titles = []\n",
    "    ratings = []\n",
    "    \n",
    "    # insert all anime titles to titles list\n",
    "    # insert all ratings to ratings list\n",
    "    for anime in info['anime']:\n",
    "        titles.append(str(anime['title']))\n",
    "        ratings.append(anime['score'])\n",
    "    \n",
    "    local = pd.DataFrame({'anime': titles,\n",
    "                          name: ratings})\n",
    "    local = local.set_index('anime')\n",
    "    df = df.combine_first(local)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "animeUser = pd.DataFrame()\n",
    "animeInfo = pd.DataFrame()\n",
    "\n",
    "# pull user animelists\n",
    "for index, row in userInfo.iterrows():\n",
    "    username = row.name\n",
    "    \n",
    "    if skip:\n",
    "        continue\n",
    "    \n",
    "    # grab anime list\n",
    "    animeUser = insertAnimeUser(animeUser, getAnimeList(username), username)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    animeUser.to_csv('animeUser.csv')\n",
    "else:\n",
    "    animeUser = pd.read_csv('animeUser.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy / Ethics Considerations\n",
    "\n",
    "In regards to the project, we are using publicly available data. However, the data needs to be cleaned as it contains location data and usernames. We will need to parse to make sure there are no odd revealing pieces of data around. Once we have accomplished this part, the data we use and display would not reveal any confidential information. Aside from this, we are in compliance with the Terms of Service provided by MyAnimeList so our data usage will be ethically safe. Furthermore, users on MyAnimeList are also able to restrict the view of their ratings list so if they did not want their ratings used by any third party application, they could simply restrict who is able to view their lists.\n",
    "\n",
    "The data results from this project do not contain user sensitive information as everything is anonymized. The purpose of the project is just to see if there is a way to draw meaningful correlations between anime or manga to create predictions. However, the results of the project may have some biased results as we will end up selecting a random population from the total users on MAL. This may create bias since it’s possible that users may have a preference to certain kinds of anime over others which would skew the data analysis and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
